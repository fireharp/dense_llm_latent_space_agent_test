"""Visual step-by-step comparison of Text vs Dense processing."""

import torch
import numpy as np
from mock_lm import MockLM
from dense_edge import DenseEdge
import time

def visualize_tensor(tensor, name, max_positions=3, max_dims=5):
    """Visualize a tensor with ASCII art."""
    print(f"\n{name} [{tensor.shape[0]}Ã—{tensor.shape[1]}]:")
    print("â”Œ" + "â”€" * 50 + "â”")
    
    for i in range(min(tensor.shape[0], max_positions)):
        values = tensor[i, :max_dims].tolist()
        formatted = [f"{v:6.3f}" for v in values]
        print(f"â”‚ Pos {i:2d}: [{', '.join(formatted)}, ...] â”‚")
    
    if tensor.shape[0] > max_positions:
        print(f"â”‚  ... ({tensor.shape[0] - max_positions} more positions) ...{' '*28}â”‚")
    
    print("â””" + "â”€" * 50 + "â”˜")
    print(f"Total values: {tensor.numel():,} floats = {tensor.numel() * 4:,} bytes")

def main():
    # Setup
    device = "cpu"
    planner = MockLM(device=device)
    solver = MockLM(device=device)
    edge = DenseEdge(d_model=896).to(device)
    
    problem = "What is 25 + 17?"
    
    print("="*70)
    print(" "*20 + "TEXT vs DENSE PROCESSING")
    print("="*70)
    print(f"\nğŸ¯ Problem: '{problem}'")
    
    # ==== TEXT-BASED PROCESSING ====
    print("\n" + "â”" + "â”"*68 + "â”“")
    print("â”ƒ" + " "*20 + "ğŸ“ TEXT-BASED APPROACH" + " "*26 + "â”ƒ")
    print("â”—" + "â”"*68 + "â”›")
    
    print("\n[STEP 1] Problem â†’ Planner â†’ Plan Text")
    print("â”€" * 40)
    
    # Simulate text generation
    plan_prompt = f"Problem: {problem}\nGenerate a plan:"
    print(f"Input: '{plan_prompt}'")
    
    time.sleep(0.1)  # Simulate processing
    plan_text = "1. Identify the numbers: 25 and 17\n2. Add them together\n3. Return the result"
    
    print(f"\nğŸ¤– Planner generates TEXT:")
    print(f"   '{plan_text}'")
    print(f"   Tokens: {len(plan_text.split())} | Bytes: {len(plan_text.encode('utf-8'))}")
    
    print("\n[STEP 2] Plan Text â†’ Solver â†’ Solution Text")
    print("â”€" * 40)
    
    solve_prompt = f"Plan: {plan_text}\nProblem: {problem}\nSolve:"
    print(f"Input: '{solve_prompt[:60]}...'")
    
    time.sleep(0.1)  # Simulate processing
    solution_text = "Following the plan:\n1. Numbers are 25 and 17\n2. 25 + 17 = 42\n3. The answer is 42"
    
    print(f"\nğŸ¤– Solver generates TEXT:")
    print(f"   '{solution_text}'")
    print(f"   Tokens: {len(solution_text.split())} | Bytes: {len(solution_text.encode('utf-8'))}")
    
    total_text_tokens = len(plan_text.split()) + len(solution_text.split())
    total_text_bytes = len(plan_text.encode('utf-8')) + len(solution_text.encode('utf-8'))
    
    print(f"\nğŸ“Š TOTAL TEXT: {total_text_tokens} tokens, {total_text_bytes} bytes")
    
    # ==== DENSE PROCESSING ====
    print("\n\n" + "â”" + "â”"*68 + "â”“")
    print("â”ƒ" + " "*20 + "ğŸ§  DENSE VECTOR APPROACH" + " "*24 + "â”ƒ")
    print("â”—" + "â”"*68 + "â”›")
    
    print("\n[STEP 1] Problem â†’ Planner â†’ Hidden States")
    print("â”€" * 40)
    
    print(f"Input: '{problem}'")
    
    # Encode to hidden states
    h_plan = planner.encode(f"Problem: {problem}\nPlan:")
    
    print(f"\nğŸ§  Planner generates HIDDEN STATES (no text!):")
    visualize_tensor(h_plan, "Planning Hidden States")
    
    print("\nğŸ’¡ These 896 numbers per position encode:")
    print("   â€¢ Understanding that 25 and 17 are numbers")
    print("   â€¢ Knowledge that '+' means addition")
    print("   â€¢ Planning steps (all implicit in vectors)")
    
    print("\n[STEP 2] Hidden States â†’ Edge â†’ Transformed Hidden States")
    print("â”€" * 40)
    
    # Transform with edge
    h_transformed = edge(h_plan)
    
    print(f"\nâš¡ Edge transforms hidden states (still no text!):")
    visualize_tensor(h_transformed, "Transformed Hidden States")
    
    print("\nğŸ’¡ The Edge learned to:")
    print("   â€¢ Apply attention between positions")
    print("   â€¢ Transform planning â†’ solving representations")
    print("   â€¢ All computation in vector space!")
    
    print("\n[STEP 3] Hidden States â†’ Solver â†’ Final Answer Only")
    print("â”€" * 40)
    
    # Decode only final answer
    final_answer = solver.decode(h_transformed, max_new_tokens=10)
    
    print(f"\nğŸ¯ Solver decodes ONLY the final answer:")
    print(f"   '{final_answer}'")
    print(f"   Tokens: {len(final_answer.split())} | Bytes: {len(final_answer.encode('utf-8'))}")
    
    # ==== COMPARISON ====
    print("\n\n" + "="*70)
    print(" "*25 + "ğŸ“Š COMPARISON")
    print("="*70)
    
    print("\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("â”‚     Metric          â”‚   Text-Based    â”‚   Dense Vector  â”‚")
    print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
    print(f"â”‚ Tokens Generated    â”‚      {total_text_tokens:3d}         â”‚       {len(final_answer.split()):3d}        â”‚")
    print(f"â”‚ Bytes (Network)     â”‚      {total_text_bytes:3d}         â”‚       {len(final_answer.encode('utf-8')):3d}        â”‚")
    print(f"â”‚ Reduction           â”‚       -         â”‚      {(1 - len(final_answer.split())/total_text_tokens)*100:.0f}%        â”‚")
    print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
    print("â”‚ Intermediate Steps  â”‚   All as text   â”‚  Hidden vectors â”‚")
    print("â”‚ Network Transfer    â”‚   All text      â”‚  Final only     â”‚")
    print("â”‚ Information Flow    â”‚   ~100 dims     â”‚   896 dims      â”‚")
    print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    
    print("\nğŸ”‘ KEY INSIGHT:")
    print("   Text approach: Every module must GENERATE then PARSE text")
    print("   Dense approach: Modules pass RICH VECTORS, decode once at end")
    
    print("\nğŸ’° COST SAVINGS:")
    print(f"   If each token costs $0.01:")
    print(f"   â€¢ Text approach: ${total_text_tokens * 0.01:.2f}")
    print(f"   â€¢ Dense approach: ${len(final_answer.split()) * 0.01:.2f}")
    print(f"   â€¢ Savings: ${(total_text_tokens - len(final_answer.split())) * 0.01:.2f} ({(1 - len(final_answer.split())/total_text_tokens)*100:.0f}%)")
    
    print("\nğŸš€ PERFORMANCE:")
    print("   â€¢ Dense keeps all computation LOCAL")
    print("   â€¢ Only final answer needs API/network")
    print("   â€¢ Hidden states are larger but stay on device")
    print("   â€¢ Perfect for distributed systems!")
    
    print("\n" + "="*70)

if __name__ == "__main__":
    main()